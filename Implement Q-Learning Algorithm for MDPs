import numpy as np

def q_learning(num_states, num_actions, P, R, terminal_states,
               alpha, gamma, epsilon, num_episodes):
    Q = np.zeros((num_states, num_actions))
    terminal_states = set(terminal_states)

    non_terminal_states = [s for s in range(num_states) if s not in terminal_states]

    for _ in range(num_episodes):
        state = np.random.choice(non_terminal_states)

        while state not in terminal_states:
            if np.random.rand() < epsilon:
                action = np.random.randint(num_actions)
            else:
                action = np.argmax(Q[state])

            next_state = np.random.choice(num_states, p=P[state, action])

            reward = R[state, action]

            best_next_q = 0 if next_state in terminal_states else np.max(Q[next_state])
            Q[state, action] += alpha * (
                reward + gamma * best_next_q - Q[state, action]
            )

            state = next_state

    return Q
