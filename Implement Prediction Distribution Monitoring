import numpy as np

def monitor_prediction_distribution(reference_preds: list, current_preds: list, n_bins: int = 10) -> dict:
    """
    Monitor prediction distribution changes between reference and current predictions.
    
    Args:
        reference_preds: List of reference prediction scores (floats between 0 and 1)
        current_preds: List of current prediction scores (floats between 0 and 1)
        n_bins: Number of bins for histogram comparison
    
    Returns:
        Dictionary with keys: 'mean_shift', 'std_ratio', 'js_divergence', 'drift_detected'
    """
    # Your code here

    ref = np.array(reference_preds, dtype=float)
    cur = np.array(current_preds, dtype=float)

    mean_shift = float(cur.mean() - ref.mean())

    ref_std = ref.std()
    cur_std = cur.std()
    std_ratio = float(cur_std / ref_std) if ref_std != 0 else 0.0

    bins = np.linspace(0, 1, n_bins + 1)

    ref_hist, _ = np.histogram(ref, bins=bins)
    cur_hist, _ = np.histogram(cur, bins=bins)

    ref_prob = (ref_hist + 1) / (ref_hist.sum() + n_bins)
    cur_prob = (cur_hist + 1) / (cur_hist.sum() + n_bins)

    m = 0.5 * (ref_prob + cur_prob)

    def kl_divergence(p, q):
        return np.sum(p * np.log(p / q))

    js_divergence = 0.5 * kl_divergence(ref_prob, m) + 0.5 * kl_divergence(cur_prob, m)

    js_divergence = float(js_divergence)

    drift_detected = js_divergence > 0.1

    return {
        'mean_shift': round(mean_shift, 4),
        'std_ratio': round(std_ratio, 4),
        'js_divergence': round(js_divergence, 4),
        'drift_detected': drift_detected
    }
    pass
